#Author: Kent O'Sullivan
#Email: osullik@umd.edu

# System Imports
import sys
import os
import unittest
import random
import string 
import argparse
import json
# Library Imports
import pandas as pd
import numpy as np
import networkit as nk
import matplotlib.pyplot as plt
from tqdm import tqdm
# User file imports

sys.path.insert(1, os.getcwd()+"/../")
sys.path.insert(1, os.getcwd()+"/../compass")
sys.path.insert(1, os.getcwd()+"/../gestalt")
sys.path.insert(1, os.getcwd()+"/../experiments")

from compass import Point, Compass
from conceptMapping import ConceptMapper
from search import InvertedIndex
from exp_compass import CompassExperimentRunner, CompassDataLoader

class DataGenerator():
    def __init__(self):
        self.compass = Compass()
        pass

    def generateMatrix(self,scaleFactor:int,edgeFactor:int):
        '''
        PURPOSE:
            Generate a random matrix of using an RMAT generator, which generates 
            scale free graphs. We repurpose the adjacency matrix to randonly initialize
            the distribution of objects in our location to follow a power-law distribution
        INPUT ARGS:
            scaleFactor - int - the size of the matrix is n = 2^scaleFactor
            edgeFactor - int - the number of edges in the graph, calculated as m = n * edgeFactor
        PROCESS:
            Initialize an RMAT generator (the four float params determine how 'skewed' the distribution will be)
                we use the standard Kroneker distribution from Graph500 pending a more detailed study of how objects
                are positioned in reality.
            Convert into a sparse matrix
            Extract all the non-zero coordinates of the sparse matrix
        OUTPUT:
            points - list of tuples of form (x,y) 
            density - float - the density of the generated graph, calculated with standard formula:
                    ((2*|E|)/(|V|*(|V|-1))) were E is edge and V is vertex

        '''
        points = []

        #Initalize the generator
        rmat = nk.generators.RmatGenerator(scaleFactor, edgeFactor, 0.57, 0.19, 0.19, 0.05) #Parameters taken from Graph500
        rmatG = rmat.generate()

        try:
            density = ((2*rmatG.numberOfEdges())/(rmatG.numberOfNodes()*(rmatG.numberOfNodes()-1)))
        except ZeroDivisionError as e:
            density = 1

        #print("DENSITY", density)

        #Generate a sparse matrix representaiton of the RMAT generated graph. 
        sm = nk.algebraic.adjacencyMatrix(rmatG,matrixType='sparse')

        #Extract row and column info from the sparse matrix and save each coordinate pair to a list
        row,col = sm.nonzero()    
        for r,c in zip(row,col):
            points.append((r,c))

        return(points, density)

    def labelNodes(self,points:list[tuple], numClasses:int, random_seed:int, queryTerms:dict=None, center_queries:bool=False)->dict:
        '''
        PURPOSE:
            Label each of the nodes generated by the RMAT algorithm to reflect the skewed-ness of real
            world distributions.
        INPUT ARGS:
            point - list of tuples of form (x,y) - the coordinates to insert a label to 
            numClasses - int - the number of distinct labels to use (e.g) a '3' would mean that all objects will
                be spread between only 3 classes
            random_seed - int - allows for replication of results; also used to determine the skewed-ness of the
                labelling distribution. Higher values will have a greater skew. 
            queryTerms - dict with keys [name, latitude, longitude] and values of lists where each index in the three
                lists corresponds to a single object. These are the query terms that we will insert to ensure 
                known true positives and false negatives in evaluation.
            center_queries - bool - tell the function whether or not
        PROCESSS:
            Using all of the letters of the english alphabet in lower case and caps (total: 52 classes) randomly select
                a subset to use as labels. 
            Use Numpy to generate an inverse Pareto distribution with 1000 samples. 
            If required, centre the query points on the centre of the location space
            For each coordinate that was passed to the function, add a label from the distribution generated, starting at
                the beginning if we have more than 1000 objects. However, if the coordinate is one of the query terms we want
                to insert, the query term will be inserted instead. 
            Add all the remaining 'query terms'
        OUTPUT
            namedPoints - dict of lists - has keys [name, latitude, longitude] and values of lists where each index in the three
                lists corresponds to a single object.
        
        '''

        RANDOM_POWER = random_seed  #the higher the random_seed value, the more skewed the power distribution
        SAMPLES = 1000
        np.random.seed(random_seed)
        random.seed(random_seed)

        namedPoints = {}
        classes = []
        labels = []
    
        #Randomly choose labels to be in the labelList
        if numClasses > len(string.ascii_letters):
            print("Maximum number of classes is", len(string.ascii_letters), "setting numClasses to:", len(string.ascii_letters))
        while len(classes) < numClasses:
            classes.append(random.choice(string.ascii_letters))
        
        #Create a sample power-law distribution, and divide it into bins representing each possible class
        s = np.random.power(RANDOM_POWER, SAMPLES)
        count, bins, ignored = plt.hist(s, bins=numClasses-1)
        binList = np.digitize(s,bins)

        names = []
        longitudes = []
        latitudes = []

        pointsDict = {}
        for i in range(0, len(points)):

            labelIndex = binList[i % len(binList)]  #Start at beginning if longer than list

            try:  
                label = classes[labelIndex-1]
            except IndexError as e:
                label = classes[labelIndex] #Handle the modulo == 0 issue
            
            pointsDict[points[i]] = label

        if queryTerms is not None:

            if center_queries == True:  #NOTE: This will break things if being used with distorted query inputs.
                min_q_x = min(queryTerms['longitude'])
                min_q_y = min(queryTerms['latitude'])
                max_q_x = max(queryTerms['longitude'])
                max_q_y = max(queryTerms['latitude'])
                centroid_q = (((min_q_x+max_q_x)/2,(min_q_y+max_q_y/2)))

                min_x = min(pointsList, key=lambda tup: tup[0])[0]
                min_y = min(pointsList, key=lambda tup: tup[1])[1]
                max_x = max(pointsList, key=lambda tup: tup[0])[0]
                max_y = max(pointsList, key=lambda tup: tup[1])[1]

                centroid_points = ((min_x+max_x)/2,(min_y+max_y)/2)

                x_mod = centroid_points[0] - centroid_q[0]
                y_mod = centroid_points[1] - centroid_q[1]

                #print("CENTROIDS", centroid_q, centroid_points)

                #print("MODS", x_mod, y_mod)

                #print("BEFORE:", queryTerms)
                for i in range(len(queryTerms.keys())):
                    queryTerms['longitude'][i] += x_mod
                    queryTerms['latitude'][i] += y_mod
                #print("AFTER:", queryTerms)
                
            for i in range(0, len(queryTerms['name'])):
                pointsDict[(queryTerms['longitude'][i],queryTerms['latitude'][i])] = queryTerms['name'][i]

        #Build the dictionary.
        for coord in pointsDict:
            #print("COORD:", coord)
            names.append(pointsDict[coord])
            longitudes.append(coord[0])
            latitudes.append(coord[1])

        namedPoints["name"] = names
        namedPoints["longitude"] = longitudes
        namedPoints["latitude"] = latitudes

        return(namedPoints)

    def saveToFile(self, experiment_name:str, saveType:str, number:int, data:dict):
        '''
        PURPOSE: 
            Save a generated location and/or query to disk. 
        INPUT ARGS: 
            experiment_name - string - the name of the experiment to be run - used to construct filepath
            saveType - string - either 'location' or 'query' - used to construct filepath
            number - int - the number of the location / query / experiment being generated
            data - dict of lists - has keys [name, latitude, longitude] and values of lists where each index in the three
                lists corresponds to a single object.
        PROCESS:
            If the directories don't exist, create them 
            Create the files
        OUTPUT:
            returns filePathToSave - string - the file path to where the file was saved
            the file that is saved to disk at 'GESTALT/data/experiments/experiment_name/saveType/saveType_number.csv'
        
        '''

        dataDirectory = ""
        for p in sys.path:
            if p.endswith("data"):
                dataDirectory = p
        
        assert dataDirectory in sys.path,"Unable to find the 'GESTALT/data' directory - does it exist?"

        experimentsDirectoryPath = os.path.join(dataDirectory, "experiments")
        assert  os.path.exists(experimentsDirectoryPath),"'data/experiments' does not exist." 

        experimentDirectoryPath = os.path.join(experimentsDirectoryPath, experiment_name)
        
        if os.path.exists(experimentDirectoryPath) == False:
            os.mkdir(experimentDirectoryPath)
        
        assert  os.path.exists(experimentDirectoryPath),"'data/experiments/'"+experiment_name+" does not exist." 

        typeDirectoryPath = os.path.join(experimentDirectoryPath, saveType)
        
        if os.path.exists(typeDirectoryPath) == False:
            os.mkdir(typeDirectoryPath)
        
        assert  os.path.exists(typeDirectoryPath),"'data/experiments/'"+experiment_name+saveType+" does not exist." 

        filePathToSave = typeDirectoryPath+"/"+saveType+str(number)+".csv"

        df_to_save = pd.DataFrame(data=data)

        df_to_save.to_csv(filePathToSave,sep=",",header=True,index=False)

        #print("FILEPATHTOSAVE", filePathToSave)

        return(filePathToSave)

    def distortQuery(self, query_dict:dict,canvas_size:int, rotation_degrees:int=0, expansion:float=0, shift_vertical:float=0, shift_horizontal:float=0):
        '''
        PURPOSE:
            Given a query, apply distortions to rotation, expansion, and lateral shifts to change it while still 
            preserving the relative positioning between points
        INPUT ARGS:
            query_dict - dict of lists - has keys [name, latitude, longitude] and values of lists where each index in the three
                lists corresponds to a single object.
            canvas_size - int - assuming a square canvas will generate a canvas_size x canvas_size surface to work with. 
            rotation_degrees - int - number from 0 to 360 that rotates the query points (and snaps them to the grid) [INACTIVE when == 0]
            expansion - float - a number from - 0 to 1 that determines how far the query should "spread" from the centre of the
                canvas (all queries will centre on the centroid as a start point.) [INACTIVE when == 0]
            shift_vertical - float - a number from -1 to 1 that defines how far up or down the canvas the query term should shift, with the maximal
                shift being this value times the maximum y value [INACTIVE when == 0
            shift_horizontal - float - a number from -1 to 1 that defines how far left or right on the canvas the query term should shift, with the maximal
                shift being this value times the maximum x value [INACTIVE when == 0]
        PROCESS:
            Apply each transformation in turn, ignoring it if == 0
        OUTPUT:
            returnQuery - dict of lists - has keys [name, latitude, longitude] and values of lists where each index in the three
                lists corresponds to a single object.
        
        '''
        #Always follow same order: 
            #Rotate
            #Expand
            #Shift Up
            #Shift Sideways

        MIN_X = 0
        MIN_Y = 0
        MAX_X = canvas_size
        MAX_Y = canvas_size
        centroid = Point('centroid', (MAX_X/2),( MAX_Y/2))

        points = []

        #Make points
        for i in range(len(query_dict['name'])):
            points.append(Point(query_dict['name'][i], query_dict['longitude'][i], query_dict['latitude'][i]))

        p_ll, p_tr, p_c = self.compass.getCentroid(points)

        #if p_c.getCoordinates() != centroid.getCoordinates():
            #print("CLUSTER",p_c.getCoordinates())
            #print("CLUSTER_BB", p_ll.getCoordinates(), p_tr.getCoordinates())
            #print("CANVAS", centroid.getCoordinates())
            #print("CANVAS_BB", (MIN_X,MIN_Y), (MAX_X,MAX_Y))

        #Rotate
        if rotation_degrees != 0:
            points = self.compass.rotateAllPoints(centroid=centroid, points=points, angle=rotation_degrees, alignToIntegerGrid=True)

        #Expand
        if expansion != 0:
            assert 0 < expansion <= 1, "expansion must be a value between 0 and 1"
            
            max_expansion = int(canvas_size*expansion)
            eachDirection = int(max_expansion/2)
            max_LL = (centroid.getCoordinates()[0]-eachDirection, centroid.getCoordinates()[1]-eachDirection) 
            max_TR = (centroid.getCoordinates()[0]+eachDirection, centroid.getCoordinates()[1]+eachDirection) 
            

            (cx,cy) = centroid.getCoordinates()

            finished = False
            while finished == False:
                for point in points:
                    #print("EXPANSION", point.dumpTuple())
                    (x,y) = point.getCoordinates()
                    if x > cx:
                        x += 1
                    if x < cx:
                        x -= 1
                    if y > cy:
                        y += 1
                    if y < cy:
                        y -= 1

                    point.updateCoordinates(x,y)
                    
                    #print("X", max_LL[0], max_TR[0])
                    #print("X", max_LL[1], max_TR[1])
                    if (x <= max_LL[0] or x >= max_TR[0] or y <= max_LL[1] or y >= max_TR[1]):
                        finished = True
                
                if finished == True:
                    break
        
        #Shift Up/Down
        if shift_vertical != 0:
            assert -1 <= shift_vertical <= 1, "shift_vertical must be between -1 and +1"

            max_shift = int(canvas_size*shift_vertical)
            each_direction = int(max_shift/2)
            
            if shift_vertical <0:
                sign = -1
            else:
                sign = 1
            
            min_y = centroid.getCoordinates()[1]-each_direction
            max_y = centroid.getCoordinates()[1]+each_direction

            finished = False
            while finished == False:    
                for point in points:
                    #print("VERT", point.dumpTuple())
                    (x,y) = point.getCoordinates()
                    y = y+(1*sign)
                    point.updateCoordinates(x,y)
                    if y <= min_y or y >= max_y:
                        finished = True
                if finished == True:
                    break

        #Shift Left/Right
        if shift_horizontal != 0:
            assert -1 <= shift_horizontal <= 1, "shift_horizontal must be between -1 and +1"

            max_shift = int(canvas_size*shift_horizontal)

            each_direction = int(max_shift/2)
            
            if shift_horizontal <0:
                sign = -1
            else:
                sign = 1
            
            min_x = centroid.getCoordinates()[0]-each_direction
            max_x = centroid.getCoordinates()[0]+each_direction
            
            finished = False
            while finished == False:    
                for point in points:
                    #print("HORIZ",point.dumpTuple())
                    (x,y) = point.getCoordinates()
                    x = x+(1*sign)
                    point.updateCoordinates(x,y)
                    if x <= min_x or x >= max_x:
                        finished = True
                if finished == True:
                    break
        
        #Regerate Dictionaries
        names = []
        longitudes = []
        latitudes = []
        returnQuery = {}

        for point in points:
            tup = point.dumpTuple()
            names.append(tup[0])
            longitudes.append(tup[1][0])
            latitudes.append(tup[1][1])

        returnQuery['name'] = names
        returnQuery['longitude'] = longitudes
        returnQuery['latitude'] = latitudes

        #print("returnQuery", returnQuery)
        return returnQuery
    

if __name__ == "__main__":

    argparser = argparse.ArgumentParser()									# initialize the argParser

    #General Params
    argparser.add_argument("--experimentName",
                            help="The name of the experiment we are running",
                            type = str,
                            required = False) 

    argparser.add_argument("--randomSeed",
                            help="number to use as random seed. Also controls the skew in the class distribution",
                            type = int,
                            required = False)

    #Location-Specific Params
    argparser.add_argument("--numLocations",
                            help="The number of Locations to create for this run",
                            type = int,
                            default=10,
                            required = False) 
    
    argparser.add_argument("--scaleFactor",
                            help="number to raise 2 to the power of to generate the graph for creating locations",
                            type = int,
                            required = False)
    
    argparser.add_argument("--edgeFactor",
                            help="number to multiple 2^scaleFactor by to get edges in graph",
                            type = int,
                            required = False)

    argparser.add_argument("--numClasses",
                            help="The number of object classes to create in any given location",
                            type=int,
                            required = False)

    #Query Specific Params
    argparser.add_argument("--numQueryTerms",
                            help="The number of Objects to add to the query term for this run",
                            type = int,
                            default=5,
                            required = False) 

    argparser.add_argument("--queryRatio",
                            help="The number (between 0 and 1) of Queries to generate as a proportion of locations",
                            type = float,
                            required = False) 

    argparser.add_argument("--numQueryDistortions",
                            help="Number between 0 and 4 that determines how many of the distortions will be (randomly) applied to the query terms",
                            type=int,
                            required = False)
    
    argparser.add_argument("--centerQueriesOnLocs",
                            help="Tell the generator whether or not to force the queries to center on the location before inserting them.",
                            action="store_true",
                            required = False)



                       

    flags = argparser.parse_args()

    SEED = flags.randomSeed
    random.seed(SEED)
    print("\n\n#############################")
    print("#GENERATING DATASET:", flags.experimentName)
    print("##############################\n")
    experiment_metadata = {}
    experiment_metadata["parameters"] = {}
    experiment_metadata["queries"] = {}
    experiment_metadata["locations"] = {}

    for parameter,value in flags.__dict__.items():
        experiment_metadata["parameters"][parameter] = value

    #Initialize the generator

    DG = DataGenerator()

    #Get the original Queries
    print("Generating queries...")
    originalQueries = {} 
    for i in tqdm(range(1, int(flags.queryRatio*flags.numLocations)+1)):
        q_names = []
        q_latitudes = []
        q_longitudes = []

        queryTerms = {}
        for j in range(0, flags.numQueryTerms):
            x = random.uniform(0.0000,float(2*flags.scaleFactor))
            y = random.uniform(0.00000,float(2*flags.scaleFactor))
            while (x,y) in queryTerms:
                x = random.uniform(0.00000,float(2*flags.scaleFactor))
                y = random.uniform(0.00000,float(2*flags.scaleFactor))
            queryTerms[(x,y)] = str(j+1)

        for q in queryTerms:
            #print("COORD:", coord)
            q_names.append(queryTerms[q])
            q_longitudes.append(q[0])
            q_latitudes.append(q[1])

        originalQueries[i] =    {"name":q_names,
                    "longitude":q_longitudes,
                    "latitude":q_latitudes}

    
    experiment_metadata["queries"]["num_queries"] = len(originalQueries.keys())
    
    #Distort the queries
    print("Applying query distortions & saving to file...")
    distortedQueries = {}
    experiment_metadata["queries"] = {}
    experiment_metadata["queries"]["query"] = {}

    for i in tqdm(range(1, len(originalQueries.keys())+1)):
        param_options = ["rotation_degrees","expansion","shift_vertical","shift_horizontal"]
        params = random.choices(param_options,k=flags.numQueryDistortions)
        param_vals = []

        if "rotation_degrees" in params:
            param_vals.append(random.randint(1,360))
        else:
            param_vals.append(0)
        if "expansion" in params:
            param_vals.append(random.random())
        else:
            param_vals.append(0)
        if "shift_vertical" in params:
            param_vals.append(random.uniform(-1,1))
        else:
            param_vals.append(0)
        if "shift_horizontal" in params:
            param_vals.append(random.uniform(-1,1))
        else:
            param_vals.append(0)

        experiment_metadata["queries"]["query"][i] = {}
        experiment_metadata["queries"]["query"][i]['name'] = "query"+str(i)
        experiment_metadata["queries"]["query"][i]["num_query_terms"] = len(originalQueries[i]['name']) 
        experiment_metadata["queries"]["query"][i]["distortions"] = {}
        experiment_metadata["queries"]["query"][i]["distortions"]["distortion"] = {}
        experiment_metadata["queries"]["query"][i]["distortions"]["distortion"] = {}
        experiment_metadata["queries"]["query"][i]["distortions"]["distortion"]["name"] = "distorted_query"+str(i)
        experiment_metadata["queries"]["query"][i]["distortions"]["distortion"]["params"] = {}
        for d, p in zip(param_options, param_vals):
            experiment_metadata["queries"]["query"][i]["distortions"]["distortion"]["params"][d] = p

                                              
        distortedQueries[i] = DG.distortQuery(query_dict=originalQueries[i],
                                                    canvas_size=2^flags.scaleFactor, 
                                                    rotation_degrees=param_vals[0], 
                                                    expansion=param_vals[1], 
                                                    shift_vertical=param_vals[2], 
                                                    shift_horizontal=param_vals[3])
    
        DG.saveToFile(experiment_name=flags.experimentName, saveType='distorted_query', number=i, data=distortedQueries[i])


    pointLists = []
    density = 0
    locations = {}

    print("Creating Locations...")
    experiment_metadata["locations"]["location"] = {}
    for i in tqdm(range(1, flags.numLocations+1)):
        G = DG.generateMatrix(scaleFactor=flags.scaleFactor, edgeFactor=flags.edgeFactor)
        pointsList = G[0]
        density = G[1]

        experiment_metadata["locations"]["location"][i] = {}
        experiment_metadata["locations"]["location"][i]["name"] = "location"+str(i)
        experiment_metadata["locations"]["location"][i]["density"] = density
            
        try:
            locations[i] = DG.labelNodes(points=pointsList,numClasses=flags.numClasses, random_seed=flags.randomSeed, queryTerms=distortedQueries[i], center_queries=flags.centerQueriesOnLocs)
            experiment_metadata["locations"]["location"][i]["embedded_query"] =  experiment_metadata["queries"]["query"][i]["distortions"]["distortion"]["name"]
            experiment_metadata["queries"]["query"][i]["true_match"] = experiment_metadata["locations"]["location"][i]["name"]

        except KeyError as e:
            locations[i] = DG.labelNodes(points=pointsList,numClasses=flags.numClasses, random_seed=flags.randomSeed, queryTerms=None,center_queries=flags.centerQueriesOnLocs)
            experiment_metadata["locations"]["location"][i]["embedded_query"] = None


        experiment_metadata["locations"]["location"][i]["num_objects"] = len(locations[i]['name'])
        print("NUM OBJECTS IN LOCATION:",len(locations[i]['name']))

    experiment_metadata["locations"]["num_locations"] = len(locations.keys())
    
    #Save to files
    print("Saving Locations to File...")
    for i in tqdm(range(1,len(locations.keys())+1)):
        DG.saveToFile(experiment_name=flags.experimentName, saveType='location', number=i, data=locations[i])
    
    print("Saving Queries to File...")
    for i in tqdm(range(1, len(originalQueries.keys())+1)):
        DG.saveToFile(experiment_name=flags.experimentName, saveType='query', number=i, data=distortedQueries[i])

    #Save the metadata
    #TODO: Make this its own function
    dataDirectory = ""
    for p in sys.path:
        if p.endswith("data"):
            dataDirectory = p
    
    assert dataDirectory in sys.path,"Unable to find the 'GESTALT/data' directory - does it exist?"

    experimentsDirectoryPath = os.path.join(dataDirectory, "experiments")
    assert  os.path.exists(experimentsDirectoryPath),"'data/experiments' does not exist." 

    experimentDirectoryPath = os.path.join(experimentsDirectoryPath, flags.experimentName)
    
    if os.path.exists(experimentDirectoryPath) == False:
        os.mkdir(experimentDirectoryPath)
    
    assert  os.path.exists(experimentDirectoryPath),"'data/experiments/'"+flags.experimentName+" does not exist." 

    with open(os.path.join(experimentDirectoryPath,flags.experimentName)+".json", "w") as outfile:
        json.dump(experiment_metadata, outfile, indent=4)