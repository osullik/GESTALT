@Article{Ding2021,
  author    = {Ding, Jian and Xue, Nan and Xia, Gui-Song and Bai, Xiang and Yang, Wen and Yang, Michael Ying and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and others},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  title     = {Object detection in aerial images: A large-scale benchmark and challenges},
  year      = {2021},
  number    = {11},
  pages     = {7778--7796},
  volume    = {44},
  comment   = {__H1:__ They seek to improve the SOTA in object detection of aerial images WRT arbitrary object rotation and the inaccurate horizontal bounding box (HBB) labelling scheme. 

__H3:__ They propose the DOTA dataset which uses orientation bounding boxes (OBB) to label 18 categories of item. 

Discipline: Object Detection in Aerial Images


"Publicly Released datasets Contain a limited number of instances and end to use images taken under ideal conditions (e.g., clear backgrounds and centered objects" --> COMMENT: Using Satellite Imagery from Maps applications gives us close to ideal. 

The object categories in DOTA-v2.0: plane, ship, storage tank, baseball diamond, tennis court, basketball court, ground track field, harbor, bridge, large vehicle, small vehicle, helicopter, roundabout, soccer ball field, swimming pool, container crane, airport and helipad. --> COMMENT: Limited Dataset. 

https://captain-whu.github.io/DOTA/},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Ding2022.pdf:PDF},
  groups    = {CMSC828T},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/iel7/34/4359286/09560031.pdf},
}

@Article{Lam2018,
  author  = {Lam, Darius and Kuzma, Richard and McGee, Kevin and Dooley, Samuel and Laielli, Michael and Klaric, Matthew and Bulatov, Yaroslav and McCord, Brendan},
  journal = {arXiv preprint arXiv:1802.07856},
  title   = {xview: Objects in context in overhead imagery},
  year    = {2018},
  comment = {__H1__ There is too much unlabelled remote sensing imagery. 


__H3__ Use of a 3 stage annotation and quality control process. 

- 60 Object Classes

- "public overhead datasets in existence typically suffer from low class ount, poor geographic diversity, few training instances, or too narrow class scope"

- Uses Horzontal Bounding Boxes

- Most of the objects are focused on port / industrial areas and disaster relief. May not be useful for what I have in mind.},
  file    = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Lam2018.pdf:PDF},
  groups  = {CMSC828T},
  url     = {https://arxiv.org/pdf/1802.07856},
}

@InProceedings{Xia2018,
  author    = {Xia, Gui-Song and Bai, Xiang and Ding, Jian and Zhu, Zhen and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and Zhang, Liangpei},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  title     = {DOTA: A large-scale dataset for object detection in aerial images},
  year      = {2018},
  pages     = {3974--3983},
  comment   = {__H1__

__H3__

Definition: Object detection in Earth Vision refers to localizing obects of interest (e.g., vehicles, airplanes) on the earthâ€™s surface and predicting their categories

_Challenges of Earth Vision:_
- Vast changes in scale of object. depending on resolution. 

- Arbitrary object rotation (i.e. no "up" like there is in regular object detection). 

- Object clustering crowds images. 

- Object count are imbalances. E.g. a 200 x 200 m car yard could have 100 cars, but a 2000 x 2000 stretch of desert might only have one or two. 

- Training data ususally in perfect condition, test is not. --> COMMENT, for pre-processing large swathes of maps, we can assume this away. 

Properties of a good dataset: 
1) a large number of images,
2) many instances per categories, 
3) properly oriented object annotation, and 
4) many different classes of objects, which make it approach to real-world applications.


Categories: plane, ship, storage tank, baseball dia-
mond, tennis court, swimming pool, ground track field, harbor, bridge, large vehicle, small vehicle, helicopter, roundabout, soccer ball field and basketball court. --> COMMENT: Limited utility in these classes.},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Xia2018.pdf:PDF},
  groups    = {CMSC828T},
  url       = {http://openaccess.thecvf.com/content_cvpr_2018/papers/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.pdf},
}

@Article{Li2020,
  author    = {Li, Ke and Wan, Gang and Cheng, Gong and Meng, Liqiu and Han, Junwei},
  journal   = {ISPRS journal of photogrammetry and remote sensing},
  title     = {Object detection in optical remote sensing images: A survey and a new benchmark},
  year      = {2020},
  pages     = {296--307},
  volume    = {159},
  comment   = {__H1__ How do we improve the ability of deep learning models to apply to the Remote Sensing Imagery Domain?  

__H3__ We proposed a new dataset for training. 

__Observations from paper__

- 20 Object Classes: 
_Windmill, Vehicle, Train Station, Tennis Court, Storage Tank, Stadium, Ship, Harbour, Ground Track Field, Golf Course, Expressway Toll Station, Expressway Service Area, Dam, Chimney, Bridge, Overpass, Basketball Court, Baseball Field, Airport, Airplane_

- "it is difficult to straight-forward transfer deep learning based object detection methods to optical remote sensing images"},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Li2020.pdf:PDF},
  groups    = {CMSC828T},
  publisher = {Elsevier},
  url       = {https://reader.elsevier.com/reader/sd/pii/S0924271619302825?token=92C775A3C0FC0E9B054597B8CECD1F9DCA518AA4E715A2B5AAFD68F889D4B63D91C5053CB6D0D2AF180B5597822C4DE8&originRegion=us-east-1&originCreation=20230312185336},
}

@InProceedings{Pink2008,
  author       = {Pink, Oliver},
  booktitle    = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
  title        = {Visual map matching and localization using a global feature map},
  year         = {2008},
  organization = {IEEE},
  pages        = {1--7},
  comment      = {__RQ__ How do we improve SLAM to support autonomous driving cars

__H1__ Use aerial imagery to generate maps in advance that the autonomous system can draw on for navigation assistance. 

__H3__ Uses aerial images to recognise lane markings and generate feature maps


__Comment__

- Not super relevant, but could we use the process of lane detection to generate simple maps of the ground so that, given an arbitrary map fragment, we are able to identify where in the larger map it comes from?},
  file         = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Pink2008.pdf:PDF},
  groups       = {CMSC828T},
  url          = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4563135},
}

@Article{Lobry2020,
  author    = {Lobry, Sylvain and Marcos, Diego and Murray, Jesse and Tuia, Devis},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  title     = {RSVQA: Visual question answering for remote sensing data},
  year      = {2020},
  number    = {12},
  pages     = {8555--8566},
  volume    = {58},
  comment   = {__RQ__
Is it possible to retrieve information from remote sensing imagery using Visual Questions answering? 

__H1__
retrieve information from remote sensing imagery using Visual Questions answering. 


__H3__

__ Quotes and Refs__
"the ability to use remote sensing data as a direct source of information is currently limited to experts within the remote sensing and computer vision communities"

"The objective of VQA is to answer a free-form and open-ended question about a given image"

"A VQA model is generally made of four distinct components: 
1) a visual feature extractor; 
2) a language feature extractor; 
3) a fusion step between the two modalities; and
4) a prediction component."

"we use the openly accessible OpenStreetMap (OSM) data containing geolocalized information provided by volunteers."

"Dataset attributes for question answer pairs:
Questions:  
1. Classify a map element to a category. 
2. Derive attributes: Shape / Size etc. 
3. Determine Relative location  to other elements. 
4. NL questions generated to match the observed elements. 
Answers: 
Extract the objects corresponding to the question type: 
1. Counting 
2. Presence
3. Area of
4. Comparison Between
5. Rural / Urban. 

"due to the source of our data (OSM),
the questions are only on a specific set of static objects (e.g., buildings and roads). Other objects of interest for applications of a VQA system to remote sensing would also include different static objects, moving objects (e.g., cars), or seasonal aspects. Including these objects would require another
source of data or manual construction of qestion/answer pairs." --> COMMENT: Justification for future work!!!!

__COMMENTS__
- Use the accessibility to experts quote.
- Their concluding remarks about the mlimitations of OSM are useful starting point to justify my idea.
- Their technical approach to VQA is relevant and useful.},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Lorby2020.pdf:PDF},
  groups    = {CMSC828T},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088993},
}

@Article{Yuan2022,
  author    = {Yuan, Zhenghang and Mou, Lichao and Wang, Qi and Zhu, Xiao Xiang},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  title     = {From easy to hard: Learning language-guided curriculum for visual question answering on remote sensing data},
  year      = {2022},
  pages     = {1--11},
  volume    = {60},
  comment   = {__RQ__
How do we improve the ability of VQA systems to operate on remote sensing data? 

__H1__

__H3__
Multi-level visual feature learning combined with self paced curriculum learning. 

__QUOTES__

""VQA for remote sensing is in its infancy"
"Two main challenges are:
_1. No object annotations are available in the RSVQA data and 2. Questions are of varying difficulty levels_

__COMMENTS__

This paper focuses on improving the models for employing VQA, but also notes that the lack of object annotations is problematic.},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Yuan2022.pdf:PDF},
  groups    = {CMSC828T},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771224},
}

@Article{Zheng2021,
  author    = {Zheng, Xiangtao and Wang, Binqiang and Du, Xingqian and Lu, Xiaoqiang},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  title     = {Mutual attention inception network for remote sensing visual question answering},
  year      = {2021},
  pages     = {1--14},
  volume    = {60},
  comment   = {__RQ__
How do we extend RSVQA to consider world-level context e.g. it's a beach. 
__H1__


__H3__
They use captioning datasets to work backwards and develop a dataset for world level VQA. 

__QUOTES__
RSVQA is more effective than caption generation as it can provide information more specifically relevant to humans. 

VQA systems have three parts: 
1. A Visual Representaiton
2. A Questions Representation. 
3. A fusion module, that checks the alignment between visual and question. 

- They ran a number of experiments to impove performance. 		

__COMMENTS__
- Lists a number of candiadate datasets. 

- This, like other VQA is focused on resolving geospatial features based on visual input. I'm more interested in determing where a combination of features is present on a map.},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Zheng2022.pdf:PDF},
  groups    = {CMSC828T},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/iel7/36/4358825/09444570.pdf},
}

@Article{Shi2017,
  author    = {Shi, Zhenwei and Zou, Zhengxia},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  title     = {Can a machine generate humanlike language descriptions for a remote sensing image?},
  year      = {2017},
  number    = {6},
  pages     = {3623--3634},
  volume    = {55},
  comment   = {__RQ__
can a machine generate humanlike language descriptions for a remote sensing image

__H1__
Generate captions for Remote Sensing Imagery. 

__H3__

__QUOTES__
Possible applications: 
- Image Retrieval
- Military Intelligence. (Convert large images into small text captions for compressed transmission)

- For most caption creation algoritims they follow the approach of: 
1. Image Understanding (region-feature based and global-feature based). 
2. Language Generation. 



__COMMENTS__

- Yes they show it's possible. 
- One of its issues is misclassifying things or miscounting things.},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Shi2017.pdf:PDF},
  groups    = {CMSC828T},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/iel7/36/4358825/07891049.pdf},
}

@InProceedings{Punjani2018,
  author    = {Punjani, Dharmen and Singh, Kuldeep and Both, Andreas and Koubarakis, Manolis and Angelidis, Iosif and Bereta, Konstantina and Beris, Themis and Bilidas, Dimitris and Ioannidis, Theofilos and Karalis, Nikolaos and others},
  booktitle = {Proceedings of the 12th workshop on geographic information retrieval},
  title     = {Template-based question answering over linked geospatial data},
  year      = {2018},
  pages     = {1--10},
  comment   = {__RQ__
Can geospatial data be used in question answering. 

__H1__
 offer a question answering service on top of linked geospatial data sources

__H3__
They create a gold standard dataset of geospatial questions. 


__QUOTES__

"A geospatial feature is an abstraction
of a real world phenomenon and can have various attributes that describe its thematic and spatial characteristics. "

"OpenStreetMap data (published
in RDF by project LinkedGeoData"

"The GIR community has been emphasizing the
need to develop techniques for answering geographic questions expressed in natural language over text data since 2004"

"no gold standard for
geospatial question answering over linked data has been proposed"

GeoSPARQL, an extension of SPARQL with a vocabulary, datatypes and functions for expressing geospatial queries over linked data.

Related Work: 
- Detecting Place Names in text
- Associating spatial language qualifiers
- Disambiguating place names. 
- Younis' work: 3 categories of questions: 
  a. Proximity
  b. Crossing
  c . Containment. 

GADM - Global Dataset of Administrative Areas. 

Question Categories: 
	- Location Retrieval
	- Asking whether a feature is in a geospatial relation with another feature.
	- Asking for features of a given class that are in a geospatial relation with another feature.
	- Asking for features of a given class that are in a geospatial rel ation with any features of another class.
	- Asking for features of a given class that are in a geospatial relation with an unspecified feature of another class which, in turn, is in another geospatial relation with a feature specified explicitly.
	- Queries that include the thematic and/or geospatial characteristics of the features that are expected as answers
	- Questions with quantities and aggregates.

__COMMENTS__

- Good to know that i can get OSM in RDF.
- Lol, References STEWARD

- They used manual mappings from OSM classed to DBPedia Classes. 

- They use Frankenstine, an implementation of QUanary which is a foral method for developing QA pipelines. 

- They use pre-defined query template patterns and map natural language inputs to those templates. Cool idea and applicable to 848e as well. 

- The NLP to Query generation part of this one is one of the main challenges. 

https://geotriples.di.uoa.gr/ could be a useful tool.},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Punjani2018.pdf:PDF},
  groups    = {CMSC828T, CMSC848E - ML for DM},
  url       = {https://dl.acm.org/doi/pdf/10.1145/3281354.3281362},
}

@InProceedings{Dsouza2021,
  author    = {Dsouza, Alishiba and Tempelmeier, Nicolas and Yu, Ran and Gottschalk, Simon and Demidova, Elena},
  booktitle = {Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
  title     = {Worldkg: A world-scale geographic knowledge graph},
  year      = {2021},
  pages     = {4475--4484},
  comment   = {__RQ__
How can we convert heterogeneous Geospatial data into a machine readable KG. 

__H1__


__H3__
Create a World Knowledge Ontology and then instantiate a knowledge graph using Open Streetmaps, Wikidata and DBPedia

__QUOTES__

We define the WorldKG ontology based on key-value pairs of the OSM schema

Ontology Creation: 
1. Scrape and Filter Key-Value Pairs
2. Infer Class Heirarchy
3. Convery property and Class Names
4. Schema Alignment with DBPedia and Wikidata. 

__COMMENTS__

Can clearly support many of the query types I care about. 

- Focused at a more macro level than I'm worried about though. 

- Suggests that using a linked data strucutre could be the way to go. 

- Presents an ontology that I can use to build on.},
  file      = {:/Users/kentosullivan/Library/Mobile Documents/com~apple~CloudDocs/UMD/2023 - Spring/CMSC828T/Project/Papers/Dsouza2021.pdf:PDF},
  groups    = {CMSC828T},
  url       = {https://dl.acm.org/doi/pdf/10.1145/3459637.3482023},
}
