\section{Related Work}
\label{section:related}


% Bellingcat
On 08 May 2023 the Open Source Intelligence platform \textit{Bellingcat}\footnote{\href{https://www.bellingcat.com/about/who-we-are/}{Bellingcat Website}} released their own version of \textit{GESTALT}, \textit{Bellingcat OSM Search}\footnote{\href{https://osm-search.bellingcat.com/}{Bellingcat OSM Search Tool}}\cite{Williams2023}. 
The blog post accompanying the release highlights the importance of pruning possible search space using objects that are known to be present. 
In their use-case, they start with a photo and attempt to geolocate it by performing the \textit{Last-Mile} search based on the presence of OSM Map Features. Their system implements a more user-friendly interface over the OSM Overpass-Turbo API and allows searchers to use dropdown lists and sliders rather than generating complicated queries. 
Their tool demonstrates the importance and utility of the problem that \textit{GESTALT} seeks to solve. It also shows how much data is already contained on OSM that can be leveraged by GESTALT. The obvious limitation is in performance. As it directly queries the OSM API, the query executes very slowly. For example, running the query to return all wineries in the swan valley region took 21 seconds to execute. In \textit{GESTALT} it takes less than 1 second. 
Their system does not address data collection, ownership assignment or concept mapping. It also doesn't allow for spatial queries that GESTALT is designed for. 
The Bellingcat tool demonstrates the utility of a system like \textit{GESTALT} and highlights how carefult consideration of data structure design is essential for developing a performant system. 


\subsection{Psychology of Geospatial Reasoning}
Several ideas from criminology, psychology and neuroscience drive the underlying idea of \textit{GESTALT} that people remember objects and anchor on those 'things' that they see while experencing a location to find it again. 

\textbf{GeoGuessr}. A popular online game called \textit{Geoguessr}\footnote{\href{https://www.geoguessr.com/}{Geoguessr Website}} demonstrates that for many people, figuring out where they are in the world can be a source of much joy. 
A 2023 journal article analysing the strategies employed by a top player identifies a number of successful strategies that are employed by a leading player \cite{Berners-Lee2023}. 
The Geoguessr problem is a distinct and in many ways reciprocal problem to the \textit{last-mile} search problem \textit{GESTALT} seeks to solve. While the last mile search assumes a general region is known, the geoguessr frequently has no idea where in the world they are, and needs to use clues from the interface (powered by google street view) to determine the country, state, county etc. that they are in. 
While not directly relevant, Geoguessr demonstrates the importance of searching for landmarks, and often even benign objects like bus stops in locating where in the world an image is. 

\textbf{Winthropping}. The Winthrop Method is a geospatial search method developed by a Captain Winthrop of the Royal Engineers for use in Northern Ireland in the 1970s\cite{Keatley2021} to detect clandestine weapons caches and concealed improvised explosive devices. 
The underlying logic is that to find something, a human has to have some method of navigating to it and that the objects in our environment help to form mental models of the terrain we can use to navigate by. 
A popular example is the closing scene of the film \textit{The Shawshank Redemption} where the protagonist Andy Dufrense provides instructions to his fellow prisoner Ellis Redding on how to find a gift left for him \textit{"It’s got a long rock wall with a big oak tree at the north end... find that spot. At the base of that wall, you’ll find a ...piece of black, volcanic glass. There’s some thing buried under it I want you to have."} 
The two reasons that Winthropping works are \textit{Affordance} and \textit{Satisficing}. Affordance refers to the interaction of an agent with its environment and in simple terms, means that certain objects will have a bigger impact on us and remain in our memory than others. 
When combined with the idea of satisficing, in which an agent makes a satisfactory or sufficient but possibly sub-optimal decision it illustrated the value of object-based search. 
We are not capable of remembering every detail of a location, so our brains will record only a few key objects or experiences for us to leverage. 
A 2013 Neuroscience study shows that when we revisit to those locations, the objects we remember serve as keys to other memories of that location\cite{Miller2013}, \textit{GESTALT} aims to exploit these geospatial aspects of memory for helping searchers to find the locations they are looking for.

\subsection{Remote Sensing Imagery}
Relevant to the data collection subsystem if \textit{GESTALT}, 2018 efforts to improve the state of the art in object detection from remote sensing imagery focused on developing datasets for training and evaluating models. 
The xView project supports the detection of 60 classes of objects\cite{Lam2018} using horizontal bounding boxes. The DOTA project supports a much more modest 20 classes\cite{Xia2018}. 
Both focus towards shipping and industrial applications and so will not generalize well. The 2021 update to the DOTA project highlighted remote sensing object detection continues to suffer from issues of arbitrary rotation of objects and the vast disparities in the clustering of objects\cite{Ding2021}. 
DOTA version 2 tries to address these issues by employing orientation bounding boxes, but is still very constrained in the classes of objects it supports. 
A separate effort by Li et. al in 2020 can detect objects less constrained to heavy industry but only accounts for 20 or so objects\cite{Li2020}. 
Overall current work on remote-sensing object detection indicates that it is still an emerging field that is incapable of supporting the labelling of micro-terrain features required for the proposed system, as a result, the object detection step is deliberately scoped out of my project.
An area growing parallel with remote sensing object detection is that of image captioning and visual question answering. 
In addition to implementing previously discussed object detection techniques, they employ alternate data sources to augment their ability to provide answers to natural language questions about remote sensing imagery. 
In 2017 Shi and Zou demonstrated that it is possible to automate caption generation for remote sensing imagery, however, their experimentation showed it to be ineffective at tasks like counting objects\cite{Shi2017}, an important requirement of micro-terrain analysis.

\subsection{Visual Question Answering}
The paper that initiated the domain of Remote Sensing Visual Question Answering (RSVQA) was published in 2020 by Lobry et. al. and showed a good ability to answer direct questions about a given remote sensing image, including area estimates, object counts and determining the relative locations of objects\cite{Lobry2020}. 
These capabilities are all useful in the concept mapping component of \textit{GESTALT}. Importantly they also incorporated geospatial information from OpenStreetMap into their system. 
A key limitation they identified is that the lack of information in OSM about specific micro-terrain features and the inability of object detection models to provide it presents a major gap holding back the advancement of the RSVQA field. 
My work may contribute towards closing that gap. Later work by Zheng et. al. and Yuan et. al highlight that RSVQA is very much in its infancy, and they focus on improving the underlying models used in RSVQA systems\cite{Zheng2021, Yuan2022}.
In addition to the gap identified by Lobry et. al, one of the limitations is the RSVQA approach is a focus on answering questions about the things that the user is already looking at. 
In my partial information use case, the user doesn’t know exactly where to look, so using the RSVQA approach would render no improvement to performance over the visual inspection itself. 
The real challenge is to identify where to look, not what they are looking at.

\subsection{Geospatial Question Answering}
 
Towards identifying where the user could be looking, the field of geospatial question answering, related to geospatial information retrieval offers promising directions. 
In 2018 Punjani et. al. sought to determine whether geospatial information could be incorporated into a question-answering system\cite{Punjani2018}. 
They used the established Frankenstein variant of the Qanary approach to developing question-answering pipelines to develop GeoQA. 
GeoQA can answer questions in several useful geospatial categories, including point queries, range queries and property-based queries. 
They built their system on linked data collected from OpenStreetMaps and WikiData. 
More recently, the efforts to develop WorldKG, a geospatial knowledge graph of the world extend the linked-data approach and allow users to generate SPARQL queries to answer complex geospatial questions across the fused knowledge of OpenStreetMaps, DBPedia and WikiData\cite{dsouza2021}. 
These linked data approaches to geospatial question answering are valuable advancements but do not include enough micro-terrain detail to satisfy the requirement of my project to allow a user to find a location based on partial information about the micro-terrain of the location.


\subsection{Pictoral Querying}
Prior work in pictoral querying shows the utility of identifying locations from maps based on knowledge of where a subset of locations on a given map are \cite{Soffer1996}. 
Their approach focuses on matching locations from a user defined pictoral input to an underlying database of maps. In the 27 years since the Pictoral Query Language was first specified, large advances in the digital storage and access to geospatial data have addressed some of the initial scale limitations that the conversion of maps to digitial pictoral representations present. For example, the role of a system like MAGELLAN \cite{Samet1998} in \textit{GESTALT} is replaced by sourcing the locations from OSM, and the requirement for a seperate system to efficently index and query map tiles like MARCO \cite{Samet1996} is now handled by OSM in its entierety. 
Additional work in pictoral querying notes the problem of searching when there are multiple instances of the objects being searched for is NP-Complete when formulated as a subgraph matching problem\cite{Folkers2000}. 
The complexity issues can be addressed by limiting the size of the initial search space to the \textit{last-mile} search over a region, and by pruning results at each step, only checking locations that pass the set-membership test of the bloom filter for example. 
The most appealing part of the work in Pictoral Querying is the query interface. Beinga able to specify queries pictorally, as a user's internal concept map, to GESTALT is likely to improve user experience and leverage the benefits of human geospatial memory and will be considered for future work. 