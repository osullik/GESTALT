\section{Implementation}
\label{section:implementation}
\textbf{(1.5 pages (5 Remain))}

The implementation section of this report discusses the engineering work conducted so far to implement the \textit{GESTALT} architecture, and reviews high level results. Specific experimental results are discussed in section \ref{section:results}.

\subsection{Data Collection}
Due to the complexity of the task and significant concurrent work in the area, the development of automated object detection and geolocation was scoped out. 
A small dataset was instead developed manually by the author as discussed in section \ref{section:dataset}. 
The data extraction, cleaning and loading was implented in Python in two parts, the \textit{KML parser} for object extraction and the \textit{Open Street Maps} query interface for location retrieval. 
The KML parser leverages the \textit{fastKML}\footnote{\href{https://pypi.org/project/fastkml/}{Fast KML PyPI Repo}} and ingests a KML file that is seperated by region (where each region is a bounding box covering an arbitrary number of locations). 
Within each region (for this test dataset) each location is seperated and its objects are stored as its childern. 
Attributes of the objects (e.g. colour, size, material) are recorded in the comments field as key:value pairs.
The KML Parser extracts the objects into dictionaries organised by location before exporting the files as JSON for future analysis. 

The OSM query interface leverages the \textit{OSMPythonTools}\footnote{\href{https://pypi.org/project/OSMPythonTools/}{OSMPythonTools PyPI Repo}}. It passes a bounding box to the OSM Overpass-Turbo API\footnote{\href{https://overpass-turbo.eu/}{Overpass-Turbo API}} and requests the relevent location nodes in the area. 
The results are arranged into a dictionary and exported as JSON for further analysis. 

Implemented so far is the translation from imputs of objects and locations, in different formats, to a common JSON format. Not yet implemented is the automatic detection and geolocation of objects. 

\subsection{Ownership Assignment}
Ownership assignment is implemented in Python as an unsupervised learning problem using clustering libraries from \textit{scikit-learn}\footnote{\href{https://pypi.org/project/scikit-learn/}{Scikit-Learn PyPI Repo}}. 
Given a collection of objects and collection of locations within a bounding box region, clustering is used to assign each object to their 'parent' location. 
Under the assumption that the number of locations is equal to the number of clusters to be formed, K-Means clustering proved to be the most effective approach. 
Where the number of object clusters does not match the number of object locations, the DBSCAN algorithm proved to be the most effective. 
When the objects have been grouped into clusters, the centroid of the object cluster is calculated. Given a KD tree of constructed from location point coordinates, a nearest neighbour search is conducted on the KD tree with a query parameter of the object centroid. The nearest location to the centroid is assigned as the 'owner'
A detailed comparison of their respective performance is in section \ref{section:results}. 

Overall, initial proof-of-concept clustering has been implemented using K-Means and DBSCAN clustering. An optimal solution to the ownership assignment problem is yet to be implemented. 
It presents an interesting, and unusual clustering problem. 
Assuming that the collection of locations is complete, and that the point coordinate of the location is central to the collection of objects that belong to that location, the clustering problem is the assignment of an arbitrary number of objects to any of a set of possible centroids. Not every centroid will have objects, and objects are not uniformly distributed. The current leading idea is re-implementing DBScan to only form clusters around pre-designated centroids, solving the problem with the current DBSCAN algorithm of merging clusters which are close together. 

Overall, the Ownership Assignment process needs to produce a data structure that will permit set membership checking for search, and set the conditions for the concept mapping process. It is the most complete component of \textit{GESTALT}. The choice of clustering algorithm needs to be refined, and loation-based bloom filters need to be implemented to support efficent search, but it is otherwise functional. 


\subsection{Concept Mapping}
Concept mapping has been partially implemented in Python leveraging the \textit{Scipy} library\footnote{\href{https://pypi.org/project/scipy/}{SciPy PyPI Repo}}. Two different approaches have been trialled. 
The first is simple dynamic arithmetic on the coordinates stored in a Pandas Dataframe. If one set of coordinates is above, below, left or right of another it is north, south, east or west respectively. 
While these calculations are in constant time for simple comparisons of known objects (e.g. "is the pond west of the bridge"), as soon as aggregations are employed, the time complexity rapidly increases. 
Queries of "Give me everything west of the duck pond" would execute in $O(N)$ time as each element has to be examined. Worst case queries would execute in $O(N\sup{2})$ time where every object is checked for its position relative to every other object. 

The second (better) approach (only partially implemented), instantiates the objects within a location into a KD-Tree. 
Assuming that the object centroid is the root, we can quickly complete queries like "Give me everything west of the duck pond" by leveraging the structure of the subtrees to return the requested set. 
Similarly, getting the relative positions of two objects searches for a common ancestor, and uses the path between the children and their ancestor node to infer their spatial relation to each other.

A third approach, designed to leverage the \textit{Neo4J Python Library}\footnote{\href{https://pypi.org/project/neo4j/}{Neo4J PyPI Repo}} to connect to a \textit{Neo4J Graph Database}\footnote{\href{https://neo4j.com/}{Neo4J Website}} but not implemented frames concept mapping as a graph traveral problem. 
In this formulation, each object is treated as a node on a graph. Weighted, labelled edges are created between each node within a given proximity threshold to the node. 
The edge labels describe the cardinal direction of the neighbouring node, and the weights the distance. 
Once the object graph is built, queries for 'give me everything west of the duck pond' would explore nodes connected by west, north and south edges freely. 
It can only traverse along an east edge so long as the total cost of travelling east would be lest than the cumulative value of the 'west' travel up to this point. 

Overall, the purpose of concept mapping is to enable geographic search over objects by explicitly representing their geospatial relatioships to each other. 
A very basic implementation using coordiante arithmetic was quickly determined to be infeasible for the large data sets that \textit{GESTALT} is expected to process. 
KD-Trees for the objects in each location have been implemented, as have the KD-Trees for locations themselves. 
This KD-Tree of KD-Trees approach preforms a natural aggregation function which, provided that regions are created consistently will allow for relative spatial queries at different levels of granularity. 
Empirical evaluation of the performance of the arithmetic, KD-Tree and Graph-based approaches is yet to be completed. 

\subsection{Search}
The search function has been implemented using the Python \textit{Pandas}\footnote{https://pypi.org/project/pandas/}{Pandas PyPI Repo} library. 
This approach assumes a single dataframe of objects and their determined locations. Because of the number of possible attributes an object can have, and the relatively few that they possess this is an sparse data structure. 
The sparseness does indicate the discriminitory power of remembering attributes. For example, a 'door' is not informative, but a 'blue door' on your favourite seaside restaurant is much more likely to prune the search space. 
Because \textit{GESTALT} is designed only for the last-mile search, and assumes a small starting region it may remain feasible to use a simple data structure like a Pandas dataframe that contains all the objects for all the locations for the region being queried. 
More work with the aggregation functions is required to determine if it can support all required aggregation queries comapring object collections. 

Semantic search has not been implemented, however the Levenshtein string distance metric (with $threshold = 0.8$) is used to check for small spelling discrepencies in input words. The priority is weighted towards retrieving all possible objects, so we accept the increased risk of mistakenly including an object to move the recall closer to 100\%. The next component to be implemented is a nearest-neighbour retreival mechanism using word embeddings. Prior work indicates that developing databases of embeddings is trivial\cite{Mueller2012}, but using existing datasets tools like word2vec, GloVe and fasttext are all able to generate embeddings over large, publicly available corpora that can be recreated. 

As discussed in the subsection on Ownership Assignment implementation, bloom filters are a much more efficent operator for set membership testing. 
The KD-Tree is more suited for geospatial queries and so the Pandas Dataframe currently supports the gaps between the two in supporting aggregation queries. More work is required to integrate these data structures into a coherent search pipeline that maximises recall while also actively pruning the search space at every step so that the searcher has the greatest chance of finding their locations of interest. Natural language querying is an active area of research that is yet to present a solution capable of effectively translating between natural language queries and their SQL solutions. Given the relatively constrained domain of this problemset, it is a good candidate for implementation as a low priority for improvement. 

\subsection{Summary of Implemenation}
The implementation of \textit{GESTALT} is incomplete, but initial work demonstrates its feasibility. The priority for future work is to implement concept mapping in full, add bloom filters to locations and implement semantic similarity searching. Improving the query interface is another 'easy win'. The work that will unlock the 'real-world' poential of \textit{GESTALT} is the automation of object geolocation. This is also the hardest part of the problem and will require substantial work. 
